<!DOCTYPE html>
<html lang="fr" xml:lang="fr">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 2 Graphique de dépendance partielle (PDP) | Interprétabilité de boîtes noires</title>
  <meta name="description" content="Projet tutoré présenté par Lucie Guillaumin et Mehdi Chebli encadré par Mr. Perduca." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 2 Graphique de dépendance partielle (PDP) | Interprétabilité de boîtes noires" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Projet tutoré présenté par Lucie Guillaumin et Mehdi Chebli encadré par Mr. Perduca." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 2 Graphique de dépendance partielle (PDP) | Interprétabilité de boîtes noires" />
  
  <meta name="twitter:description" content="Projet tutoré présenté par Lucie Guillaumin et Mehdi Chebli encadré par Mr. Perduca." />
  

<meta name="author" content="Lucie Guillaumin &amp; Mehdi Chebli" />


<meta name="date" content="2021-01-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="importance-des-variables-dans-les-modèles-prédictifs.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interprétabilité de boites noires</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#remerciements"><i class="fa fa-check"></i>Remerciements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="graphique-de-dépendance-partielle-pdp.html"><a href="graphique-de-dépendance-partielle-pdp.html"><i class="fa fa-check"></i><b>2</b> Graphique de dépendance partielle (PDP)</a><ul>
<li class="chapter" data-level="2.1" data-path="graphique-de-dépendance-partielle-pdp.html"><a href="graphique-de-dépendance-partielle-pdp.html#définition"><i class="fa fa-check"></i><b>2.1</b> Définition</a><ul>
<li class="chapter" data-level="" data-path="graphique-de-dépendance-partielle-pdp.html"><a href="graphique-de-dépendance-partielle-pdp.html#exemple"><i class="fa fa-check"></i>Exemple</a></li>
<li class="chapter" data-level="" data-path="graphique-de-dépendance-partielle-pdp.html"><a href="graphique-de-dépendance-partielle-pdp.html#cas-particulier"><i class="fa fa-check"></i>Cas particulier</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="graphique-de-dépendance-partielle-pdp.html"><a href="graphique-de-dépendance-partielle-pdp.html#avantages"><i class="fa fa-check"></i><b>2.2</b> Avantages</a></li>
<li class="chapter" data-level="2.3" data-path="graphique-de-dépendance-partielle-pdp.html"><a href="graphique-de-dépendance-partielle-pdp.html#inconvénients"><i class="fa fa-check"></i><b>2.3</b> Inconvénients</a></li>
<li class="chapter" data-level="2.4" data-path="graphique-de-dépendance-partielle-pdp.html"><a href="graphique-de-dépendance-partielle-pdp.html#en-r"><i class="fa fa-check"></i><b>2.4</b> En <code>R</code></a></li>
<li class="chapter" data-level="2.5" data-path="graphique-de-dépendance-partielle-pdp.html"><a href="graphique-de-dépendance-partielle-pdp.html#exemples"><i class="fa fa-check"></i><b>2.5</b> Exemples</a><ul>
<li class="chapter" data-level="2.5.1" data-path="graphique-de-dépendance-partielle-pdp.html"><a href="graphique-de-dépendance-partielle-pdp.html#exemple-1-utilisation-de-deux-boites-noires-différentes-comme-modèles-sur-le-jeu-de-données-weather"><i class="fa fa-check"></i><b>2.5.1</b> Exemple 1 : Utilisation de deux boites noires différentes comme modèles sur le jeu de données <code>weather</code></a></li>
<li class="chapter" data-level="2.5.2" data-path="graphique-de-dépendance-partielle-pdp.html"><a href="graphique-de-dépendance-partielle-pdp.html#exemple-2-utilisation-de-deux-boites-noires-différentes-comme-modèles-sur-le-jeu-de-données-mtcars"><i class="fa fa-check"></i><b>2.5.2</b> Exemple 2 : Utilisation de deux boites noires différentes comme modèles sur le jeu de données <code>mtcars</code></a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="graphique-de-dépendance-partielle-pdp.html"><a href="graphique-de-dépendance-partielle-pdp.html#espérance-conditionnelle-individuelle-ice"><i class="fa fa-check"></i><b>2.6</b> Espérance conditionnelle individuelle (ICE)</a><ul>
<li class="chapter" data-level="2.6.1" data-path="graphique-de-dépendance-partielle-pdp.html"><a href="graphique-de-dépendance-partielle-pdp.html#définition-1"><i class="fa fa-check"></i><b>2.6.1</b> Définition</a></li>
<li class="chapter" data-level="2.6.2" data-path="graphique-de-dépendance-partielle-pdp.html"><a href="graphique-de-dépendance-partielle-pdp.html#exemple-ice-avec-le-jeu-de-données-weather-et-comme-boite-noire-une-forêt-aléatoire"><i class="fa fa-check"></i><b>2.6.2</b> Exemple : ICE avec le jeu de données <code>weather</code> et comme boite noire une forêt aléatoire</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="importance-des-variables-dans-les-modèles-prédictifs.html"><a href="importance-des-variables-dans-les-modèles-prédictifs.html"><i class="fa fa-check"></i><b>3</b> Importance des variables dans les modèles prédictifs</a><ul>
<li class="chapter" data-level="3.1" data-path="importance-des-variables-dans-les-modèles-prédictifs.html"><a href="importance-des-variables-dans-les-modèles-prédictifs.html#définition-2"><i class="fa fa-check"></i><b>3.1</b> Définition</a></li>
<li class="chapter" data-level="3.2" data-path="importance-des-variables-dans-les-modèles-prédictifs.html"><a href="importance-des-variables-dans-les-modèles-prédictifs.html#avantages-2"><i class="fa fa-check"></i><b>3.2</b> Avantages</a></li>
<li class="chapter" data-level="3.3" data-path="importance-des-variables-dans-les-modèles-prédictifs.html"><a href="importance-des-variables-dans-les-modèles-prédictifs.html#inconvénients-2"><i class="fa fa-check"></i><b>3.3</b> Inconvénients</a></li>
<li class="chapter" data-level="3.4" data-path="importance-des-variables-dans-les-modèles-prédictifs.html"><a href="importance-des-variables-dans-les-modèles-prédictifs.html#en-r-1"><i class="fa fa-check"></i><b>3.4</b> En <code>R</code></a></li>
<li class="chapter" data-level="3.5" data-path="importance-des-variables-dans-les-modèles-prédictifs.html"><a href="importance-des-variables-dans-les-modèles-prédictifs.html#exemples-1"><i class="fa fa-check"></i><b>3.5</b> Exemples</a><ul>
<li class="chapter" data-level="3.5.1" data-path="importance-des-variables-dans-les-modèles-prédictifs.html"><a href="importance-des-variables-dans-les-modèles-prédictifs.html#exemple-1-pfi-sur-les-données-iris"><i class="fa fa-check"></i><b>3.5.1</b> Exemple 1 : PFI sur les données <code>iris</code></a></li>
<li class="chapter" data-level="3.5.2" data-path="importance-des-variables-dans-les-modèles-prédictifs.html"><a href="importance-des-variables-dans-les-modèles-prédictifs.html#exemple-2-pfi-sur-les-données-fifa"><i class="fa fa-check"></i><b>3.5.2</b> Exemple 2 : PFI sur les données <code>fifa</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="substitut-local-lime.html"><a href="substitut-local-lime.html"><i class="fa fa-check"></i><b>4</b> Substitut local (LIME)</a><ul>
<li class="chapter" data-level="4.1" data-path="substitut-local-lime.html"><a href="substitut-local-lime.html#définition-3"><i class="fa fa-check"></i><b>4.1</b> Définition</a></li>
<li class="chapter" data-level="4.2" data-path="substitut-local-lime.html"><a href="substitut-local-lime.html#avantages-3"><i class="fa fa-check"></i><b>4.2</b> Avantages</a></li>
<li class="chapter" data-level="4.3" data-path="substitut-local-lime.html"><a href="substitut-local-lime.html#inconvénients-3"><i class="fa fa-check"></i><b>4.3</b> Inconvénients</a></li>
<li class="chapter" data-level="4.4" data-path="substitut-local-lime.html"><a href="substitut-local-lime.html#en-r-2"><i class="fa fa-check"></i><b>4.4</b> En <code>R</code></a></li>
<li class="chapter" data-level="4.5" data-path="substitut-local-lime.html"><a href="substitut-local-lime.html#exemples-2"><i class="fa fa-check"></i><b>4.5</b> Exemples</a><ul>
<li class="chapter" data-level="4.5.1" data-path="substitut-local-lime.html"><a href="substitut-local-lime.html#exemple-1-lime-sur-le-jeu-de-données-weather"><i class="fa fa-check"></i><b>4.5.1</b> Exemple 1 : LIME sur le jeu de données <code>weather</code></a></li>
<li><a href="substitut-local-lime.html#exemple-2-lime-sur-le-jeu-de-données-iris">Exemple 2 : LIME sur le jeu de données <code>iris</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="références.html"><a href="références.html"><i class="fa fa-check"></i><b>5</b> Références</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interprétabilité de boîtes noires</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="graphique-de-dépendance-partielle-pdp" class="section level1">
<h1><span class="header-section-number">Chapitre 2</span> Graphique de dépendance partielle (PDP)</h1>
<div id="définition" class="section level2">
<h2><span class="header-section-number">2.1</span> Définition</h2>
<p>Le graphique de dépendance partielle permet de comprendre les variables importantes dans un modèle donné. Effectivement, le PDP permet d'examiner la relation entre une variable explicative (voire deux) et le modèle à expliquer pour lequel nous calculons des prédictions.<br />
Supposons que l'on souhaite comprendre l'importance d'une variable dans un modèle donné. Le PDP construit le modèle en faisant la moyenne des autres variables prédictives, à l'exception d'une variable prédictive choisie : il peut aider à identifier comment une variable affecte notre modèle. En effet, si l'on observe un plateau sur le PDP alors pour les valeurs associées la variable n'est pas utilisée pour prédire : elle n'a pas d'effet dans le modèle.</p>
<p>Soit <span class="math inline">\(x_S\)</span> une variable pour laquelle le PDP va être tracé, cette variable est donc fixée. En général, dans l'ensemble de <span class="math inline">\(S\)</span> il n'y a qu'une ou deux caractéristiques. Ces caractéristiques sont celles pour lesquelles on veut connaître l'effet sur la prédiction.<br />
Soit <span class="math inline">\(x_C\)</span> toutes les autres variables utilisées dans le modèle de machine learning, ce sont donc ces variables que nous allons faire varier.<br />
Soit <span class="math inline">\(\hat{f}\)</span> la boîte noire que l'on cherche à expliquer.</p>
<p>On définit la fonction de dépendance partielle par :<br />
<span class="math display">\[
\hat{f}_{x_S}(x_S) = \mathbb{E}[\hat{f}(x_S, x_C)] = \int \hat{f}(x_S,x_C) d\mathbb{P}(x_C)
\]</span></p>
<div id="exemple" class="section level3 unnumbered">
<h3>Exemple</h3>
<p>Soit <span class="math inline">\(x = x_S\)</span> et <span class="math inline">\(z = x_C \in \{0,1\}\)</span>. <span class="math display">\[
\mathbb{E}_z[\hat{f}(x,z)] = \hat{f}(x,0)\mathbb{P}(z=0) + \hat{f}(x,1)\mathbb{P}(z=1) \\
=\hat{f}(x) \text{ : fonction qui dépend de x}
\]</span> En réalité, <span class="math inline">\(\hat{f}(x)\)</span> définie comment <span class="math inline">\(\hat{f}\)</span> dépend en &quot;moyenne&quot; de <span class="math inline">\(x\)</span>, c'est à dire quand l'on fait varier toutes les autres variables.</p>
<p>On définit maintenant la méthode de <code>Monte Carlo</code>. <span class="math display">\[  
\mathbb{E}[g(X)] = \int g(x)F(x)dx \text{ où } F(x) \text{ densité de } X  
\]</span> Pour estimer cette espérance, on peut :<br />
- tirer <span class="math inline">\(x_1,...,x_n\)</span> selon <span class="math inline">\(F\)</span><br />
- calculer <span class="math inline">\(g(x_1),...,g(x_n)\)</span><br />
- <span class="math inline">\(\hat{\mathbb{E}}[g(x)] = \frac{1}{n} \sum_{i=1}^n g(x_i)\)</span></p>
<p>A l'aide de la méthode de Monte Carlo, nous pouvons définir la fonction partielle <span class="math inline">\(\hat{f}(x_S)\)</span> qui est estimée en calculant les moyennes dans les données d'entraînement : <span class="math display">\[
\hat{f}_{x_S}(x_S) = \frac{1}{n}\sum_{i=1}^n \hat{f}(x_S, x_C^{(i)})
\]</span> Cette fonction nous indique pour une ou plusieurs valeurs données de <span class="math inline">\(S\)</span> quel est l'effet marginal moyen sur la prédiction.<br />
Ici, les <span class="math inline">\(x_c^{(i)}\)</span> sont les valeurs réelles des caractéristiques de l'ensemble de données pour les caractéristiques qui ne nous intéressent pas, et n est le nombre d'occurrences dans l'ensemble de données.</p>
</div>
<div id="cas-particulier" class="section level3 unnumbered">
<h3>Cas particulier</h3>
<p>Dans le cas particulier où notre modèle n'est pas une boîte noire, la méthode de Monte Carlo illustre bien le fait que nous retombons sur quelque chose que nous connaissons déjà et donc il n'est pas nécessaire d'utiliser un PDP.<br />
Nous allons le confirmer avec le choix d'un modèle linéaire comme modèle de machine learning.</p>
<p>Soient <span class="math inline">\(\hat{f}(x,z) = a+bx+cz\)</span> et <span class="math inline">\(\psi\)</span> la densité de <span class="math inline">\(z\)</span>.<br />
<span class="math display">\[
\int\hat{f}(x,z)\psi(z)dz = \int (a+bx+cz)\psi(z)dz \\
= a\int\psi(z)dz + bx\int\psi(z)dz + c\int z\psi(z)dz \\
= a + bx + c \mathbb{E}[z]
\]</span> On utilise donc la méthode de Monte Carlo pour estimer <span class="math inline">\(\mathbb{E}[z]\)</span>, et c'est quelque chose que l'on sait faire aisément.</p>
</div>
</div>
<div id="avantages" class="section level2">
<h2><span class="header-section-number">2.2</span> Avantages</h2>
<p>Les graphiques de dépendance partielle sont faciles à implémenter et à interpréter.</p>
<p>Ils fonctionnent pour les variables catégorielles.</p>
<p>Si la variable pour laquelle vous avez calculé le PDP n'est pas corrélée avec les autres caractéristiques, alors les PDP représentent parfaitement comment la variable influence la prédiction en moyenne.</p>
<p>Le calcul des graphiques de dépendance partielle a une interprétation causale. Nous intervenons sur une fonctionnalité et mesurons les évolutions des prédictions. Ainsi, nous analysons la relation causale entre la caractéristique et la prédiction. La relation est causale pour le modèle (parce que nous modélisons explicitement le résultat en fonction des caractéristiques) mais pas nécessairement pour le monde réel.</p>
</div>
<div id="inconvénients" class="section level2">
<h2><span class="header-section-number">2.3</span> Inconvénients</h2>
<p>En raison de techniques de visualisation limitées et de la restriction de la perception humaine à un maximum de trois dimensions, seules une ou deux caractéristiques peuvent raisonnablement être affichées dans un PDP.</p>
<p>Le PDP repose sur une hypothèse d’indépendance entre les variables, qui est rarement vérifiée en pratique. Si les variables sont corrélées entre elles, la fonction de dépendance partielle produira des points de données irréalistes (par exemple il est peu probable qu'une personne qui mesure 2 mètres pèse 50kg). Nous avons donc, ici, deux problèmes :</p>
<ul>
<li><p>Le premier problème est que le couple <span class="math inline">\((x,y_i)\)</span> avec <span class="math inline">\(x\)</span> fixé soit invraisemblable : c'est à dire que ce n'est pas quelque chose qui représente la réalité. On peut résoudre ce problème en prenant un intervalle fixé de y qui se tient autour de <span class="math inline">\(x\)</span>. Le <strong>M-Plot</strong> est donc une solution.</p></li>
<li><p>Le second problème est du à l'influence de <span class="math inline">\(x\)</span> sur <span class="math inline">\(y\)</span>. On imagine que <span class="math inline">\(x\)</span> n'a pas d'influence dans la prédiction : on s'attend alors que le PDP soit constant. Mais si <span class="math inline">\(y\)</span> a de l'influence alors on observera un PDP non constant : cela constitue un problème. Afin de le résoudre, les graphiques <strong>ALE</strong> proposent une bonne solution.</p></li>
</ul>
<p>Le PDP masque les effets hétérogènes entre les variables, en effet, il ne montre que les effets marginaux moyens. Une solution à ce problème est le graphique <strong>ICE</strong> présenté plus loin dans ce chapitre.</p>
</div>
<div id="en-r" class="section level2">
<h2><span class="header-section-number">2.4</span> En <code>R</code></h2>
<p>En <code>R</code>, nous utilisons le package <code>iml</code> pour implémenter les graphique de dépendance partielle. Ci-dessous nous pouvons trouver un exemple de code avec pour boite noire une forêt aléatoire :</p>
<pre><code>algo_FA = randomForest(formula, data, importance = TRUE)
predictor = Predictor$new(model = algo_FA, data)
pdp = FeatureEffect$new(predictor, feature, method = &quot;pdp&quot;, grid.size = 30)

p1 = pdp$plot()

pdp$set.feature(&quot;nom variable&quot;)
p2 = pdp$plot()

gridExtra::grid.arrange(p1, p2, nol = 2)</code></pre>
<p>Il existe aussi d'autres packages pour implémenter des PDP comme le package <code>pdp</code> ou bien <code>DALEX</code>.<br />
Du coté de <code>Python</code>, les PDP sont intégrés dans <code>scikit-learnet</code>.</p>
</div>
<div id="exemples" class="section level2">
<h2><span class="header-section-number">2.5</span> Exemples</h2>
<p>Il existe plusieurs méthodes de traitements pour les modèles de machine learning, on souhaite comparer pour un même jeu de données si les différents algorithmes nous renvoient aux même résultats et surtout essayer de comprendre quelle méthode de machine learning est le plus adaptée pour chaque data frame.</p>
<div id="exemple-1-utilisation-de-deux-boites-noires-différentes-comme-modèles-sur-le-jeu-de-données-weather" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Exemple 1 : Utilisation de deux boites noires différentes comme modèles sur le jeu de données <code>weather</code></h3>
<p>Nous choisissons pour notre premier exemple le jeu de données <code>weather</code> du package <code>nycflights13</code>. Il représente les données météorologiques horaires pour les trois aéroports de New York : EWR, LGA et JFK.<br />
Nous allons commencer par implémenter une forêt aléatoire puis un algorithme SVM comme modèles de machine learning. Nous voulons prédire la température (en Fahrenheit) des aéroports de New York et utiliser le diagramme de dépendance partielle afin de visualiser les relations que le modèle a apprises. L'influence des caractéristiques que nous avons choisies sur la température sont illustrés dans les figures suivantes.</p>
<div id="construction-du-pdp-avec-comme-boite-noire-une-forêt-aléatoire" class="section level4 unnumbered">
<h4>Construction du PDP avec comme boite noire une forêt aléatoire</h4>
<div class="figure"><span id="fig:unnamed-chunk-4"></span>
<img src="02-pdp_ice_files/figure-html/unnamed-chunk-4-1.png" alt="PDP pour le modèle de prédiction de la température dans les aéroports de New York avec la méthode des forêts aléatoires." width="960" />
<p class="caption">
Figure 2.1: PDP pour le modèle de prédiction de la température dans les aéroports de New York avec la méthode des forêts aléatoires.
</p>
</div>
<p>En <code>figure 1</code>, nous obtenons un graphique de dépendance partielle où nous avons prédit la température (en F) dans les différents aéroports de New York avec comme modèle de boite noire une forêt aléatoire.<br />
On utilise ce graphique pour visualiser les relations que le modèle a apprises.<br />
Nous avons prédit la température à l'aide des variables <code>Point de rosée</code>, <code>Humidité</code>, <code>Vitesse du vent</code> en Miles par heure ainsi que les <code>Aéroports</code>.<br />
On rappelle que les marques sur l'axe des <span class="math inline">\(x\)</span> indiquent la distribution des données.<br />
On voit donc sur ces graphiques que :</p>
<ul>
<li><p>Plus le point de rosée augmente, plus la température augmente. Ce qui paraît logique : la rosée apparaît le matin, là où les températures sont les plus faibles.</p></li>
<li><p>Plus l’humidité augmente, plus la température diminue. On remarque quand même à partir de 75-80% d'humidité un palier, ce qui indique que la température stagne.</p></li>
<li><p>Plus la vitesse du vent augmente, plus la température diminue. Ce qui paraît logique encore une fois. De plus, on remarque qu'à partir de 30 mph la température stagne.</p></li>
<li><p>Concernant la variable catégorielle <code>Aéroport</code>, on remarque que peu importe l'aéroport que l'on choisit, ils montrent un effet similaire sur les prévisions du modèle.</p></li>
</ul>
</div>
<div id="visualisation-de-la-dépendance-partielle-de-deux-fonctionnalités-à-la-fois" class="section level4 unnumbered">
<h4>Visualisation de la dépendance partielle de deux fonctionnalités à la fois</h4>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-5"></span>
<img src="02-pdp_ice_files/figure-html/unnamed-chunk-5-1.png" alt="PDP de la prédiction de la température et l'intéraction de l'humidité et de la vitesse du vent." width="768" />
<p class="caption">
Figure 2.2: PDP de la prédiction de la température et l'intéraction de l'humidité et de la vitesse du vent.
</p>
</div>
<p>En <code>figure 2</code>, nous observons un graphique de dépendance partielle pour la prédiction de la température dans les aéroports de New York avec deux fonctionnalités qui sont l'<code>Humidité</code> et la <code>Vitesse du vent</code> avec pour modèle de machine learning une forêt aléatoire.<br />
Ce graphique nous montre que plus l'humidité augmente et plus la vitesse du vent augmente, alors la température diminue.</p>
</div>
<div id="construction-du-pdp-avec-comme-boite-noire-un-algorithme-svm" class="section level4 unnumbered">
<h4>Construction du PDP avec comme boite noire un algorithme SVM</h4>
<div class="figure"><span id="fig:unnamed-chunk-6"></span>
<img src="02-pdp_ice_files/figure-html/unnamed-chunk-6-1.png" alt="PDP pour le modèle de prédiction de la température dans les aéroports de New York avec la méthode SVM." width="960" />
<p class="caption">
Figure 2.3: PDP pour le modèle de prédiction de la température dans les aéroports de New York avec la méthode SVM.
</p>
</div>
<p>Nous modélisons à l'aide d'un algorithme SVM notre PDP, de même que pour les conclusions obtenues via une forêt aléatoire, nous pouvons constater les mêmes informations qu'apporte chaque variable et ses effets sur la prédiction de la température :</p>
<ul>
<li><p>Le point de rosée a un effet positif sur la prédiction de la température</p></li>
<li><p>L'humidité joue aussi son rôle puisqu'il y a une interaction négative avec la variable température</p></li>
<li><p>La vitesse du vent influence de manière positive la prédiction de la température</p></li>
<li><p>L'aéroport n'intervient dans la compréhension de la température puisqu'elle n'a aucun effet sur cette dernière</p></li>
</ul>
</div>
</div>
<div id="exemple-2-utilisation-de-deux-boites-noires-différentes-comme-modèles-sur-le-jeu-de-données-mtcars" class="section level3">
<h3><span class="header-section-number">2.5.2</span> Exemple 2 : Utilisation de deux boites noires différentes comme modèles sur le jeu de données <code>mtcars</code></h3>
<p>Nous choisissons pour notre second exemple la base de données <code>mtcars</code>, qui indique la consommation de carburant (en miles par gallon) de 32 automobiles (modèles 1973-74), à laquelle nous appliquons un modèle de machine learning : les forêts aléatoires.<br />
Nous voulons prédire le nombre de cylindres d'une voiture et utiliser le diagramme de dépendance partielle pour visualiser les relations que le modèle a apprises. L'influence des caractéristiques d'une voiture sur le nombre de cylindres prévus sont illustrées dans les figures suivantes.</p>
<div id="construction-du-pdp-avec-comme-boite-noire-une-forêt-aléatoire-1" class="section level4 unnumbered">
<h4>Construction du PDP avec comme boite noire une forêt aléatoire</h4>
<div class="figure"><span id="fig:unnamed-chunk-8"></span>
<img src="02-pdp_ice_files/figure-html/unnamed-chunk-8-1.png" alt="PDP pour le modèle de prédiction du nombre de cylindres d'une voiture en fonction de son poids, son déplacement, sa puissance et le rapport du pont arrière avec la méthode des forêts aléatoires." width="960" />
<p class="caption">
Figure 2.4: PDP pour le modèle de prédiction du nombre de cylindres d'une voiture en fonction de son poids, son déplacement, sa puissance et le rapport du pont arrière avec la méthode des forêts aléatoires.
</p>
</div>
<p>Il est important ici de se placer dans le contexte, nous essayons de prédire le nombre de cylindres présents dans une voiture à l'aide des autres variables présentes dans le dataframe. Comme le nombre de cylindres est fixé, nous avons donc dû créer une variable catégorielle pour classer chaque prédiction.<br />
Nous étudions variable par variable pour décrire leurs comportements.</p>
<p>La variable <code>Poids</code>, pour chaque niveau, n'influence pas le cylindre d'un véhicule que l'on ait une voiture plus ou moins lourde : cela n'a pas d'importance.</p>
<p>Pour ce qui est de la variable <code>Volume du moteur</code>, les probabilités d'affectation à un véhicule à quatre cylindres sont quasiment les mêmes quelque soit le volume du moteur. Il n'y a donc aucune interaction particulière.<br />
Pour affecter un véhicule à six cylindres, les probabilités diminuent lorsque le volume du moteur augmente : on note donc un effet négatif.<br />
En revanche, les voitures prédites avec huit cylindres voient leurs probabilités d'affectation augmenter via l'augmentation du volume du moteur : nous avons ici une interaction positive.</p>
<p>Dans le cadre de la variable <code>Puissance</code>, pour des véhicules prédits à quatre cylindres il n'existe pas de lien pouvant affirmer que l'augmentation de la puissance implique une prédiction des véhicules à quatre cylindres.<br />
En revanche, pour prédire un véhicule à six cylindres nous constatons que la puissance joue un rôle dans cette expérience. Lorsqu'elle augmente cela diminue la probabilité de prédire six cylindres dans un véhicule, on en conclut donc un lien négatif.<br />
Enfin, pour les grosses cylindrés nous constatons que les probabilités associées à la prédiction de huit cylindres augmentent lorsque la voiture est très puissante, c'est donc un effet positif qui s'exerce entre ces deux variables.</p>
<p>Enfin avec la variable <code>mpg</code>, affecter un véhicule à quatre cylindres est impacté par l'augmentation de mpg. En effet, les probabilités de prédire quatre cylindres augmente au fur et à mesure que mpg s'élève aussi. Pour six cylindres nous avons la conclusion inverse, les probabilités de prédire six cylindres diminuent en même temps que mpg. En revanche pour les véhicules affecté à huit cylindres il n'y a aucune importance sur la valeur que peut prendre mpg, les probabilités sont les mêmes.</p>
</div>
<div id="construction-du-pdp-avec-comme-boite-noire-un-algorithme-svm-1" class="section level4 unnumbered">
<h4>Construction du PDP avec comme boite noire un algorithme SVM</h4>
<div class="figure"><span id="fig:unnamed-chunk-9"></span>
<img src="02-pdp_ice_files/figure-html/unnamed-chunk-9-1.png" alt="PDP pour le modèle de prédiction du nombre de cylindres d'une voiture en fonction de son poids, son déplacement, sa puissance et le rapport du pont arrière avec la méthode SVM." width="960" />
<p class="caption">
Figure 2.5: PDP pour le modèle de prédiction du nombre de cylindres d'une voiture en fonction de son poids, son déplacement, sa puissance et le rapport du pont arrière avec la méthode SVM.
</p>
</div>
<p>De même que pour le traitement précédent nous construisons aussi un PDP à l'aide de l’algorithme SVM.<br />
Dans l'hypothèse de savoir si nous obtenons les mêmes informations nous analysons donc nos résultats.</p>
<p>Nous reprenons donc notre analyse en nous intéressant au comportement de la variable <code>Poids</code>. Pour un véhicule de plus en plus lourd la probabilité de prédire quatre cylindres diminue elle aussi de plus en plus, nous avons donc le témoignage de l'effet de corrélation négatif.<br />
À contrario, pour la prédiction des véhicules de six et huit cylindres, plus leurs poids augmentent et plus leurs probabilités de prédire six ou huit cylindres augmentent.<br />
Dans l'idée général nous voyons que les grosses voitures impliquent d'avoir plus de cylindres.</p>
<p>Ici, nous regardons l'impact des variables <code>Déplacement</code> et <code>Puissance</code>.<br />
Pour ce qui est des voitures prédites à quatre ou six cylindres, elles témoignent le même comportement. En effet, pour des déplacements plus grands les probabilités de prédire que tel véhicule à quatre ou six cylindres décroissent : ce qui met en évidence une influence négative.<br />
En revanche, pour les voitures prédites à huit cylindres c'est l'exact opposé, avec de nombreux déplacements cela croît la probabilité d'être affecté à un véhicule comprenant huit cylindres.<br />
Ici, on peut voir l'isolement des véhicules citadins standards et les véhicules apprêtés pour faire de gros déplacement.</p>
<p>Pour ce qui est de la variable <code>mpg</code>, nous constatons une tendance positive pour prédire des voitures à quatre cylindres, plus on augmente mpg et plus l'on a de chance d'affecter une voiture à quatre cylindres. Ce qui est tout le contraire pour prédire les véhicules à six et huit cylindres qui, eux, ont un effet négatif lorsque mpg augmente.</p>
</div>
</div>
</div>
<div id="espérance-conditionnelle-individuelle-ice" class="section level2">
<h2><span class="header-section-number">2.6</span> Espérance conditionnelle individuelle (ICE)</h2>
<div id="définition-1" class="section level3">
<h3><span class="header-section-number">2.6.1</span> Définition</h3>
<p>Un inconvénient du graphique de dépendance partielle est qu'il ne montre que les effets marginaux moyens, en effet il masque les effets hétérogènes entre les variables. Pour résoudre ce problème, il existe les tracés d'espérance conditionnelle individuelle (ICE).<br />
Les tracés ICE affichent une ligne pour chaque observation. Ils vont montrer comment la prédiction de l'observation varie lorsqu'une entité varie : c'est donc l'équivalent d'un PDP pour des observations de données individuelles. En conclusion, un PDP est la moyenne des lignes d'un graphique ICE.</p>
<p>Une définition plus formelle serait : pour chaque <span class="math inline">\(\{(x_S^{(i)}, x_C^{(i)})\}_{i=1}^n\)</span> la courbe <span class="math inline">\(\hat{f}_S^{(i)}\)</span> est tracée contre <span class="math inline">\(x_S^{(i)}\)</span> tandis que <span class="math inline">\(x_C^{(i)}\)</span> reste fixé.</p>
<div id="avantages-1" class="section level4">
<h4><span class="header-section-number">2.6.1.1</span> Avantages</h4>
<p>La méthode ICE, étant une dérivée du PDP, est plus facile à interpréter. En effet, sur le graphe est tracé les prédictions pour chaque instance. Cela permet aussi d'identifier les relations hétérogènes entre <span class="math inline">\(x_S^{(i)}\)</span>.</p>
</div>
<div id="inconvénients-1" class="section level4">
<h4><span class="header-section-number">2.6.1.2</span> Inconvénients</h4>
<p>Sur les modèles ICE comme nous avons plusieurs tracés sur les graphiques, il n'est par conséquent pas faisable d'ajouter une deuxième variable sur le graphe. Cela rendrait une lecture impossible car nous ne verrons rien suite aux nombreux tracés qui surchargent le graphique.</p>
<p>De même que pour les traitements PDP, la méthode ICE nécessite aussi l'hypothèse d'indépendance des variables qui n'est pas vraiment vérifiée dans la pratique.</p>
</div>
<div id="programmation" class="section level4">
<h4><span class="header-section-number">2.6.1.3</span> Programmation</h4>
<p>En <code>R</code>, nous utilisons le package <code>iml</code> pour implémenter les tracés d'espérance conditionnelle individuelle (ICE). Ci-dessous nous pouvons trouver un exemple de code avec pour boite noire une forêt aléatoire :</p>
<pre><code>algo_FA = randomForest(formula, data, importance = TRUE)
predictor = Predictor$new(model = algo_FA, data)
pdp = FeatureEffect$new(predictor, feature, method = &quot;ice&quot;, grid.size = 30)

p1 = pdp$plot()

pdp$set.feature(&quot;nom variable&quot;)
p2 = pdp$plot()

gridExtra::grid.arrange(p1, p2, nol = 2)</code></pre>
<p>Il existe aussi d'autres packages pour implémenter des ICE comme le package <code>pdp</code>, <code>ICEbox30</code>.<br />
Du coté de <code>Python</code>, les ICE sont intégrés dans <code>scikit-learnet</code>.</p>
</div>
</div>
<div id="exemple-ice-avec-le-jeu-de-données-weather-et-comme-boite-noire-une-forêt-aléatoire" class="section level3">
<h3><span class="header-section-number">2.6.2</span> Exemple : ICE avec le jeu de données <code>weather</code> et comme boite noire une forêt aléatoire</h3>
<div class="figure"><span id="fig:unnamed-chunk-10"></span>
<img src="02-pdp_ice_files/figure-html/unnamed-chunk-10-1.png" alt="ICE pour le modèle de prédiction de la température (en F) avec la méthode des forêts aléatoires." width="960" />
<p class="caption">
Figure 2.6: ICE pour le modèle de prédiction de la température (en F) avec la méthode des forêts aléatoires.
</p>
</div>
<p>En <code>figure 6</code>, nous obtenons un tracé ICE où nous avons prédit la température (en F) dans les différents aéroports de New York avec comme modèle de boite noire une forêt aléatoire. Chaque ligne représente une température.<br />
Toutes les instances représentées dans le modèle ICE nous indiquent les mêmes informations que dans le modèle PDP :</p>
<ul>
<li><p>Le point de rosée a toujours un effet positif sur la prédiction de la température</p></li>
<li><p>L'humidité joue aussi son rôle puisqu'il y a une tendance négative avec la variable température</p></li>
<li><p>La vitesse du vent influence de manière positive la prédiction de la température</p></li>
</ul>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="importance-des-variables-dans-les-modèles-prédictifs.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Interpretabilite-boite-noire.pdf", "Interpretabilite-boite-noire.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
